{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "   ...  pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
       "0  ...   44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
       "1  ...   38  6000  NaN   no   no   no  good   no   no            ckd  \n",
       "2  ...   31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
       "3  ...   32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
       "4  ...   35  7300  4.6   no   no   no  good   no   no            ckd  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(\"data/KidneyData.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ckd</th>\n",
       "      <th>notckd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ckd  notckd\n",
       "3     1       0\n",
       "9     1       0\n",
       "11    1       0\n",
       "14    1       0\n",
       "20    1       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[\"classification\"].copy()\n",
    "\n",
    "data_binary_encoded = pd.get_dummies(data)\n",
    "data_binary_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_binary_encoded[\"ckd\"]\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidney_data = df.drop(columns=[\"classification\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kidney_data = kidney_data.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>bu</th>\n",
       "      <th>sc</th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>...</th>\n",
       "      <th>dm_no</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>cad_no</th>\n",
       "      <th>cad_yes</th>\n",
       "      <th>appet_good</th>\n",
       "      <th>appet_poor</th>\n",
       "      <th>pe_no</th>\n",
       "      <th>pe_yes</th>\n",
       "      <th>ane_no</th>\n",
       "      <th>ane_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>131.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>61.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age    bp     sg   al   su    bgr     bu   sc    sod  pot  ...  dm_no  \\\n",
       "3   48.0  70.0  1.005  4.0  0.0  117.0   56.0  3.8  111.0  2.5  ...      1   \n",
       "9   53.0  90.0  1.020  2.0  0.0   70.0  107.0  7.2  114.0  3.7  ...      0   \n",
       "11  63.0  70.0  1.010  3.0  0.0  380.0   60.0  2.7  131.0  4.2  ...      0   \n",
       "14  68.0  80.0  1.010  3.0  2.0  157.0   90.0  4.1  130.0  6.4  ...      0   \n",
       "20  61.0  80.0  1.015  2.0  0.0  173.0  148.0  3.9  135.0  5.2  ...      0   \n",
       "\n",
       "   dm_yes cad_no cad_yes  appet_good  appet_poor  pe_no  pe_yes  ane_no  \\\n",
       "3       0      1       0           0           1      0       1       0   \n",
       "9       1      1       0           0           1      1       0       0   \n",
       "11      1      1       0           0           1      0       1       1   \n",
       "14      1      0       1           0           1      0       1       1   \n",
       "20      1      0       1           0           1      0       1       0   \n",
       "\n",
       "    ane_yes  \n",
       "3         1  \n",
       "9         1  \n",
       "11        0  \n",
       "14        0  \n",
       "20        1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = kidney_data.copy()\n",
    "\n",
    "# data1 = kidney_data[[\"rbc\", \"pc\", \"pcc\", \"ba\", \"htn\", \"dm\", \"cad\", \"appet\", \"pe\", \"ane\"]].copy()\n",
    "\n",
    "data_binary_encoded1 = pd.get_dummies(data1, columns=[\"rbc\", \"pc\", \"pcc\", \"ba\", \"htn\", \"dm\", \"cad\", \"appet\", \"pe\", \"ane\"])\n",
    "data_binary_encoded1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo',\n",
       "       'pcv', 'wc', 'rc', 'rbc_abnormal', 'rbc_normal', 'pc_abnormal',\n",
       "       'pc_normal', 'pcc_notpresent', 'pcc_present', 'ba_notpresent',\n",
       "       'ba_present', 'htn_no', 'htn_yes', 'dm_no', 'dm_yes', 'cad_no',\n",
       "       'cad_yes', 'appet_good', 'appet_poor', 'pe_no', 'pe_yes', 'ane_no',\n",
       "       'ane_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_binary_encoded1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo',\n",
       "       'pcv', 'wc', 'rc', 'rbc_abnormal', 'pc_abnormal', 'pcc_notpresent',\n",
       "       'ba_notpresent', 'htn_no', 'dm_no', 'cad_no', 'appet_good', 'pe_no',\n",
       "       'ane_no'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_binary_data = data_binary_encoded1.drop(columns=['rbc_normal', 'pc_normal', 'pcc_present', 'ba_present', 'htn_yes', 'dm_yes','cad_yes', 'appet_poor', 'pe_yes', 'ane_yes'])\n",
    "kidney_binary_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = kidney_binary_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(kidney_binary_data, target, random_state=630)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.15465450931230557, 'al'),\n",
       " (0.15318564596788212, 'hemo'),\n",
       " (0.13500221282906694, 'pcv'),\n",
       " (0.1343730469932806, 'sc'),\n",
       " (0.12052029775663148, 'rc'),\n",
       " (0.06496705456860692, 'bu'),\n",
       " (0.05639548747302218, 'htn_no'),\n",
       " (0.05301237549106996, 'sg'),\n",
       " (0.022101054649446943, 'bgr'),\n",
       " (0.021116930787408356, 'pc_abnormal'),\n",
       " (0.02058771867130072, 'dm_no'),\n",
       " (0.014864825411759337, 'sod'),\n",
       " (0.009434322109647968, 'pe_no'),\n",
       " (0.009037748293702534, 'rbc_abnormal'),\n",
       " (0.005444204248847402, 'wc'),\n",
       " (0.005149864418718055, 'su'),\n",
       " (0.005071331954336809, 'bp'),\n",
       " (0.00479734255560068, 'appet_good'),\n",
       " (0.00317711802463817, 'pot'),\n",
       " (0.002125223177888743, 'age'),\n",
       " (0.0020486287107838964, 'cad_no'),\n",
       " (0.0015994131526639753, 'ane_no'),\n",
       " (0.0013336434413907022, 'ba_notpresent'),\n",
       " (0.0, 'pcc_notpresent')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Travis Young\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 1 0 0 1 1 0 0 0]\n",
      "First 10 Actual labels: [1, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0            1       1\n",
       "1            1       1\n",
       "2            1       1\n",
       "3            0       0\n",
       "4            0       0\n",
       "5            1       1\n",
       "6            1       1\n",
       "7            0       0\n",
       "8            0       0\n",
       "9            0       0\n",
       "10           0       0\n",
       "11           0       0\n",
       "12           0       0\n",
       "13           0       0\n",
       "14           0       0\n",
       "15           0       0\n",
       "16           0       0\n",
       "17           0       0\n",
       "18           0       0\n",
       "19           0       0\n",
       "20           0       0\n",
       "21           1       1\n",
       "22           1       1\n",
       "23           0       0\n",
       "24           0       0\n",
       "25           1       1\n",
       "26           0       0\n",
       "27           0       0\n",
       "28           1       1\n",
       "29           0       0\n",
       "30           0       0\n",
       "31           1       1\n",
       "32           0       0\n",
       "33           0       0\n",
       "34           0       0\n",
       "35           1       1\n",
       "36           1       1\n",
       "37           0       0\n",
       "38           0       0\n",
       "39           0       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.975\n"
     ]
    }
   ],
   "source": [
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.96      0.98        28\n",
      "    positive       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.96      0.98      0.97        40\n",
      "weighted avg       0.98      0.97      0.98        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "y_train_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=24, activation='relu', input_dim=24))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples\n",
      "Epoch 1/100\n",
      "118/118 - 1s - loss: 0.5138 - accuracy: 0.7458\n",
      "Epoch 2/100\n",
      "118/118 - 0s - loss: 0.4516 - accuracy: 0.8559\n",
      "Epoch 3/100\n",
      "118/118 - 0s - loss: 0.3991 - accuracy: 0.9322\n",
      "Epoch 4/100\n",
      "118/118 - 0s - loss: 0.3543 - accuracy: 0.9492\n",
      "Epoch 5/100\n",
      "118/118 - 0s - loss: 0.3147 - accuracy: 0.9915\n",
      "Epoch 6/100\n",
      "118/118 - 0s - loss: 0.2799 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "118/118 - 0s - loss: 0.2510 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "118/118 - 0s - loss: 0.2240 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "118/118 - 0s - loss: 0.1995 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "118/118 - 0s - loss: 0.1783 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "118/118 - 0s - loss: 0.1593 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "118/118 - 0s - loss: 0.1424 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "118/118 - 0s - loss: 0.1271 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "118/118 - 0s - loss: 0.1138 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "118/118 - 0s - loss: 0.1023 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "118/118 - 0s - loss: 0.0920 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "118/118 - 0s - loss: 0.0828 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "118/118 - 0s - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "118/118 - 0s - loss: 0.0681 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "118/118 - 0s - loss: 0.0620 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "118/118 - 0s - loss: 0.0567 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "118/118 - 0s - loss: 0.0519 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "118/118 - 0s - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "118/118 - 0s - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "118/118 - 0s - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "118/118 - 0s - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "118/118 - 0s - loss: 0.0349 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "118/118 - 0s - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "118/118 - 0s - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "118/118 - 0s - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "118/118 - 0s - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "118/118 - 0s - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "118/118 - 0s - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "118/118 - 0s - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "118/118 - 0s - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "118/118 - 0s - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "118/118 - 0s - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "118/118 - 0s - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "118/118 - 0s - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "118/118 - 0s - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "118/118 - 0s - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "118/118 - 0s - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "118/118 - 0s - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "118/118 - 0s - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "118/118 - 0s - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "118/118 - 0s - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "118/118 - 0s - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "118/118 - 0s - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "118/118 - 0s - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "118/118 - 0s - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "118/118 - 0s - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "118/118 - 0s - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "118/118 - 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "118/118 - 0s - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "118/118 - 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "118/118 - 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "118/118 - 0s - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "118/118 - 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "118/118 - 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "118/118 - 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "118/118 - 0s - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "118/118 - 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "118/118 - 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "118/118 - 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "118/118 - 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "118/118 - 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "118/118 - 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "118/118 - 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "118/118 - 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "118/118 - 0s - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "118/118 - 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "118/118 - 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "118/118 - 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "118/118 - 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "118/118 - 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "118/118 - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "118/118 - 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "118/118 - 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "118/118 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "118/118 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "118/118 - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "118/118 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "118/118 - 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "118/118 - 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "118/118 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "118/118 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "118/118 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "118/118 - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "118/118 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "118/118 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "118/118 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "118/118 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "118/118 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "118/118 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "118/118 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "118/118 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "118/118 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "118/118 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "118/118 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "118/118 - 0s - loss: 0.0026 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2011f669308>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=24, activation='relu', input_dim=24))\n",
    "deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples\n",
      "Epoch 1/100\n",
      "118/118 - 1s - loss: 0.6339 - accuracy: 0.7966\n",
      "Epoch 2/100\n",
      "118/118 - 0s - loss: 0.5892 - accuracy: 0.8475\n",
      "Epoch 3/100\n",
      "118/118 - 0s - loss: 0.5462 - accuracy: 0.8729\n",
      "Epoch 4/100\n",
      "118/118 - 0s - loss: 0.5033 - accuracy: 0.9068\n",
      "Epoch 5/100\n",
      "118/118 - 0s - loss: 0.4625 - accuracy: 0.9492\n",
      "Epoch 6/100\n",
      "118/118 - 0s - loss: 0.4216 - accuracy: 0.9746\n",
      "Epoch 7/100\n",
      "118/118 - 0s - loss: 0.3843 - accuracy: 0.9831\n",
      "Epoch 8/100\n",
      "118/118 - 0s - loss: 0.3483 - accuracy: 0.9915\n",
      "Epoch 9/100\n",
      "118/118 - 0s - loss: 0.3149 - accuracy: 0.9915\n",
      "Epoch 10/100\n",
      "118/118 - 0s - loss: 0.2830 - accuracy: 0.9915\n",
      "Epoch 11/100\n",
      "118/118 - 0s - loss: 0.2537 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "118/118 - 0s - loss: 0.2269 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "118/118 - 0s - loss: 0.2022 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "118/118 - 0s - loss: 0.1801 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "118/118 - 0s - loss: 0.1601 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "118/118 - 0s - loss: 0.1424 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "118/118 - 0s - loss: 0.1264 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "118/118 - 0s - loss: 0.1127 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "118/118 - 0s - loss: 0.1005 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "118/118 - 0s - loss: 0.0896 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "118/118 - 0s - loss: 0.0803 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "118/118 - 0s - loss: 0.0723 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "118/118 - 0s - loss: 0.0653 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "118/118 - 0s - loss: 0.0589 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "118/118 - 0s - loss: 0.0536 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "118/118 - 0s - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "118/118 - 0s - loss: 0.0448 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "118/118 - 0s - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "118/118 - 0s - loss: 0.0380 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "118/118 - 0s - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "118/118 - 0s - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "118/118 - 0s - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "118/118 - 0s - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "118/118 - 0s - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "118/118 - 0s - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "118/118 - 0s - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "118/118 - 0s - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "118/118 - 0s - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "118/118 - 0s - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "118/118 - 0s - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "118/118 - 0s - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "118/118 - 0s - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "118/118 - 0s - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "118/118 - 0s - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "118/118 - 0s - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "118/118 - 0s - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "118/118 - 0s - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "118/118 - 0s - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "118/118 - 0s - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "118/118 - 0s - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "118/118 - 0s - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "118/118 - 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "118/118 - 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "118/118 - 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "118/118 - 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "118/118 - 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "118/118 - 0s - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "118/118 - 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "118/118 - 0s - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "118/118 - 0s - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "118/118 - 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "118/118 - 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "118/118 - 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "118/118 - 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "118/118 - 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "118/118 - 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "118/118 - 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "118/118 - 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "118/118 - 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "118/118 - 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "118/118 - 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "118/118 - 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "118/118 - 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "118/118 - 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "118/118 - 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "118/118 - 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "118/118 - 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "118/118 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "118/118 - 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "118/118 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "118/118 - 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "118/118 - 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "118/118 - 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "118/118 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "118/118 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "118/118 - 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "118/118 - 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "118/118 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "118/118 - 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "118/118 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "118/118 - 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "118/118 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "118/118 - 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "118/118 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "118/118 - 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "118/118 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "118/118 - 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "118/118 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "118/118 - 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "118/118 - 0s - loss: 0.0019 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x201209fd988>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Normal Neural Network - Loss: 0.0032674197107553484, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 - 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Deep Neural Network - Loss: 0.002782899048179388, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
